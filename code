import torch.nn as nn
import torch
from torchvision.transforms import transforms
from torch.utils.data import DataLoader
import torchvision
import torch.nn.functional as F
import os
import time
from torch import optim
from sklearn import metrics
import numpy as np
import torch.backends.cudnn as cudnn
import cv2
from torch.optim.lr_scheduler import MultiStepLR
from skimage.metrics import peak_signal_noise_ratio as compare_psnr
from skimage.metrics import structural_similarity as compare_ssim
from skimage.metrics import mean_squared_error as compare_mse

# 启用CuDNN（CUDA Deep Neural Network library）加速。
cudnn.enabled = True

class encoder(nn.Module):
    def __init__(self,in_channels,out_channels):
        super(encoder,self).__init__()
        
        self.conv1 = nn.Conv2d(in_channels,out_channels,kernel_size=3,stride = 1,padding=1)
        self.bn1 = nn.BatchNorm2d(out_channels)
        
        self.conv2 = nn.Conv2d(out_channels,out_channels,kernel_size = 3,stride = 1,padding=1)
        self.bn2 = nn.BatchNorm2d(out_channels)
    
    def forward(self,x):
        x=self.conv1(x)
        x=self.bn1(x)
        x=F.relu(x)
        x=self.conv2(x)
        x=self.bn2(x)
        x=F.relu(x)
        return x
    
class decoder(nn.Module):
    def __init__(self,in_channels,out_channels):
        super(decoder,self).__init__()
        
        self.conv1 = nn.ConvTranspose2d(in_channels,out_channels,kernel_size =2,stride =2)
        self.bn1 = nn.BatchNorm2d(out_channels)
        
    def forward(self,x):
        x=self.conv1(x)
        x=self.bn1(x)
        x=F.relu(x)
        return x
    
class Unet(nn.Module):
    def __init__(self):
        super(Unet,self).__init__()
        self.convlayer1 = encoder(1,8)
        self.convlayer2 = encoder(8,16)
        self.convlayer3 = encoder(16,32)
        self.convlayer4 = encoder(32,64)
        self.convlayer5 = encoder(64,128)
        
        self.convlayer6 = encoder(128,64)
        self.convlayer7 = encoder(64,32)
        self.convlayer8 = encoder(32,16)
        self.convlayer9 = encoder(16,8)
        self.convlayer10 = nn.Conv2d(8,1,kernel_size=3,stride=1,padding=1)
        
        self.deconv1 = decoder(128,64)
        self.deconv2 = decoder(64,32)
        self.deconv3 = decoder(32,16)
        self.deconv4 = decoder(16,8)
        
        self.sigmoid = nn.Sigmoid()
        
    def forward(self,x):
        c1 = self.convlayer1(x)
        p1 = F.max_pool2d(c1,2)
        
        c2 = self.convlayer2(p1)
        p2 = F.max_pool2d(c2,2)
        
        c3 = self.convlayer3(p2)
        p3 = F.max_pool2d(c3,2)
        
        c4 = self.convlayer4(p3)
        p4 = F.max_pool2d(c4,2)
        
        c5 = self.convlayer5(p4)
        
        ct1 = self.deconv1(c5)
        concat1 = torch.cat([ct1,c4],dim=1)
        c6 = self.convlayer6(concat1)
        
        ct2 = self.deconv2(c6)
        concat2 = torch.cat([ct2,c3],dim=1)
        c7 = self.convlayer7(concat2)
        
        ct3 = self.deconv3(c7)
        concat3 = torch.cat([ct3,c2],dim=1)
        c8 = self.convlayer8(concat3)
        
        ct4 = self.deconv4(c8)
        concat4 = torch.cat([ct4,c1],dim=1)
        c9 = self.convlayer9(concat4)
        
        output = self.convlayer10(c9)
        output = self.sigmoid(output)
        return output

def train(model, train_loader, optimizer, criterion):
	running_loss = 0	
	model.train()		
	cudnn.benchmark = True
	for i, (data, target) in enumerate(train_loader):
		data = data.cuda()
		optimizer.zero_grad()	
		output = model(data)	
		target = data.clone()	
		target = target * 0.3081 + 0.1307	
		loss = criterion(output, target)	
		loss.backward()		
		optimizer.step()	
		running_loss += loss.item()		
	model.train_loss['epoch_loss'].append(running_loss / (i + 1))	

def val(epoch, model, val_loader, criterion, save_image_dir):
	model.eval()	
	cudnn.benchmark = False		
	val_loss = 0
	psnr = []
	ssim = []
	rmse = []
	mae = []
	save_image_dir_epoch = save_image_dir + 'epoch{}/'.format(epoch)
    
	if not os.path.exists(save_image_dir_epoch):
		os.makedirs(save_image_dir_epoch)

	with torch.no_grad():
		for i, (data, _) in enumerate(val_loader):
			data = data.cuda()
			output = model(data)	
			target = data.clone()	
			target = target * 0.3081 + 0.1307	
			val_loss += criterion(output, target).item() # sum up batch loss
			# 计算验证损失值,并将其累加到val_loss中


			psnr.append(compare_psnr(target.squeeze().cpu().numpy().astype(np.float32), output.squeeze().cpu().numpy().astype(np.float32)))
			ssim.append(compare_ssim(target.squeeze().cpu().numpy().astype(np.float32), output.squeeze().cpu().numpy().astype(np.float32),data_range=32))
			rmse.append(np.sqrt(compare_mse(target.squeeze().cpu().numpy().astype(np.float32), output.squeeze().cpu().numpy().astype(np.float32))))
			mae.append(criterion(output, target).item())

			if i < 200:
				outputs_save = np.clip(output[0].cpu().numpy(), 0, 1) * 255
				target_save = np.clip(target[0].cpu().numpy(), 0, 1) * 255
				cv2.imwrite(save_image_dir_epoch + 'e{}_{}_o.jpg'.format(epoch, i), outputs_save.squeeze().astype(np.uint8))
				cv2.imwrite(save_image_dir_epoch + 'e{}_{}_t.jpg'.format(epoch, i), target_save.squeeze().astype(np.uint8))

	val_loss /= (i + 1)
	# 将计算得到的验证损失和评估指标存储在模型的val_loss字典和measure字典中的相应列表中。
	model.val_loss['epoch_loss'].append(val_loss)
	model.measure['psnr'].append(np.mean(psnr))
	model.measure['ssim'].append(np.mean(ssim))
	model.measure['rmse'].append(np.mean(rmse))
	model.measure['mae'].append(np.mean(mae))


def save_checkpoint(state, snapshot_dir, filename='.pth.tar'):
	torch.save(state, '{}/{}'.format(snapshot_dir, filename))



    
def main():
	batchsize = 100
	test_batchsize = 80
	epoches = 100
	image_size = 32

	transform = transforms.Compose([transforms.Resize(image_size),
									transforms.ToTensor(),
									transforms.Normalize((0.1307,), (0.3081,)), ])
	trainset = torchvision.datasets.FashionMNIST(root='./data/fashionmnist', train=True, download=True,
												 transform=transform)
	trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize, shuffle=True, num_workers=2)
	testset = torchvision.datasets.FashionMNIST(root='./data/fashionmnist', train=False, download=True,
												transform=transform)
	testloader = torch.utils.data.DataLoader(testset, batch_size=test_batchsize, shuffle=False, num_workers=2)

    #训练模型保存目录
	trained_model_dir = 'unet/' 
	#训练信息记录文件路径
	train_info_record = 'unet/index.txt'
    #指定结果图像保存的目录
	save_image_dir = 'unet/results/'
	model_path = 'unet/model_best.pth.tar'

	if not os.path.exists(trained_model_dir):
		os.makedirs(trained_model_dir)

	if not os.path.exists(save_image_dir):
		os.makedirs(save_image_dir)
        

	net = Unet()
	net.cuda()
	optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)
	criterion = nn.L1Loss()

	net.train_loss = {
		'epoch_loss': []
	}
	net.val_loss = {
		'epoch_loss': []
	}
	net.measure = {
		'psnr': [],
		'ssim': [],
		'rmse': [],
		'mae': []
	}

	if os.path.isfile(model_path):
		checkpoint = torch.load(model_path)
		net.load_state_dict(checkpoint['state_dict'])	# 将加载的模型参数加载到网络模型net中。
		epoch = checkpoint['epoch']
		val(epoch, net, testloader, criterion, save_image_dir)
		print(' sample: %d psnr: %.2f  ssim: %.4f  rmse: %.6f mae: %.6f' % (
			len(testloader.dataset), net.measure['psnr'][-1], net.measure['ssim'][-1], net.measure['rmse'][-1], net.measure['mae'][-1]))
		return

	# train begin
	print('training begin')
	scheduler = MultiStepLR(optimizer, milestones=[50, 70, 85], gamma=0.1)
	for epoch in range(epoches):
		scheduler.step()	
		start = time.time()
		train(net, trainloader, optimizer, criterion)
		end = time.time()
		print('epoch: %d sample: %d cost %.5f seconds  loss: %.5f' % (
		epoch, len(trainloader.dataset), (end - start), net.train_loss['epoch_loss'][-1]))

		val(epoch, net, testloader, criterion, save_image_dir)
		print(' eval sample: %d test_loss: %.5f psnr: %.2f  ssim: %.4f rmse: %.6f mae: %.6f' % (
		len(testloader.dataset), net.val_loss['epoch_loss'][-1], net.measure['psnr'][-1], net.measure['ssim'][-1], net.measure['rmse'][-1], net.measure['mae'][-1]))
		# save checkpoint
		state = {
			'state_dict': net.state_dict(),
			'optimizer': optimizer.state_dict(),
			'epoch': epoch + 1,
			'train_loss': net.train_loss,
			'val_loss': net.val_loss,
			'measure': net.measure
		}
		# save model
		save_checkpoint(state, trained_model_dir, filename='model_now.pth.tar')
		# 如果当前轮数的PSNR指标比之前的轮数都要好,保存最佳模型
		if len(net.measure['psnr']) > 1 and net.measure['psnr'][-1] >= max(net.measure['psnr'][:-1]):
			save_checkpoint(state, trained_model_dir, filename='model_best.pth.tar')

		with open(train_info_record, 'a') as f:
			f.write(
				'lr:{}, epoch:{}, train_loss:{:.4f}, val_loss:{:.6f}, psnr:{:.2f}, ssim:{:.2f}, rmse:{:.6f},mae: {:.6f}'.format(
					optimizer.param_groups[0]['lr'], epoch, net.train_loss['epoch_loss'][-1],
					net.val_loss['epoch_loss'][-1], net.measure['psnr'][-1], net.measure['ssim'][-1], net.measure['rmse'][-1], net.measure['mae'][-1]) + '\n'
			)

if __name__ == "__main__":
	main()

